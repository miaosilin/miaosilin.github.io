---
title: Game Theory
url: Game theory_url
tags: Game Theory
categories: Game Theory
date:   2020-06-18 
---

## 概念界定

一般意义上的博弈：
$$
\Gamma=\left(N, V, E, x^{0},\left(V_{i}\right)_{i \in N \cup\{0\}},\left(p_{x}\right)_{x \in V_{0}},\left(U_{i}^{J}\right)_{i \in N}^{j=1, \ldots, k_{i}}, O, u\right)
$$
N：参与人；  V：节点；  E：边； $x^0$初始节点； V：决策点； p：概率分布； U信息集； O:结果； u：效用函数



#### 信息结构

完美信息博弈（下棋）不完美（打牌）：每一个信息集都是单点集；确定信息：自然不参与行动；不完全信息：自然首先参与行动；

完美记忆：行动人记得自己的行为；

完美信息一定是完美记忆，完美记忆不一定是完美信息。

#### 博弈、均衡分类

动态博弈的核心问题：可信任性

完全信息静态博弈；不完全信息静态博弈； 完全信息动态博弈； 不完全信息动态博弈。

子博弈的起点信息集是单点集；并且不能拆分任何一个信息集；静态博弈是特殊的动态博弈；合作博弈是特殊的非合作博弈；

每一个信息集对应一个行动选择：$s_{i}: \mathcal{U}_{i} \rightarrow \bigcup_{j=1}^{k_{i}} A\left(U_{i}^{j}\right)$

纯策略纳什均衡：$u_{i}\left(s^{*}\right) \geq u_{i}\left(s_{i}, s_{-i}^{*}\right)$（每个人的选择都是针对其他人的选择的最优反应。）

混合策略：有限个参与人随机选择某个行动

行为策略：参与者的行为策略是一个函数，它将他的每个信息集映射为在该信息集上可能采取的一系列行动的概率分布。

均衡的精炼：把均衡变得更加完美

逆向归纳法：looking forward， reasoning backward

序贯理性：每个人在每一步中都追求条件期望效用最大化，并且是动态理性：不是一开始就想好的。

共同知识：$\omega \in K_{i_{1}} K_{i_{2}} \ldots K_{i_{l-1}} K_{i_{l}} A$ 我知道你知道我知道你知道我知道我知道......

同时博弈：一个信息集有多个参与人或者参与人不知道别的参与人的行动，也可看做同时博弈。

## 主要命题

零和博弈中，每个人的极大极小值=极小极大值=纳什均衡。（鞍点：对于策略s1是极大值，对于策略s2是极小值）
$$
\underline{v}:=\max _{s_{1} \in S_{\mathrm{I}}} \min _{s_{\mathrm{I}} \in S_{\mathrm{II}}} u\left(s_{\mathrm{I}}, s_{\mathrm{II}}\right) \\
\bar{v}:=\min _{s_{\mathrm{II}} \in S_{\mathrm{II}}} \max _{s_{\mathrm{I}} \in S_{\mathrm{I}}} u\left(s_{\mathrm{I}}, s_{\mathrm{II}}\right)
$$
库恩定理：完美记忆使得行为策略等价于混合策略

***均衡的精炼： 纳什均衡——子博弈完美均衡——完美贝叶斯均衡——序贯均衡——完美（颤抖手）均衡——正恰均衡***

子博弈完美均衡（SPE)：***排除不可置信威胁***，在子博弈中不愿偏离，在***子博弈中也是纳什均衡***：子博弈完美均衡的存在不需要完美信息，只需要完美记忆
$$
u_{i}\left(\sigma^{*} \mid x\right) \geq u_{i}\left(\sigma_{i}, \sigma_{-i}^{*} \mid x\right)
$$
但有些时候，子博弈完美均衡也是纳什均衡，会得到很荒唐的结果，因此需要再精炼。

***完美贝叶斯均衡***：只适用于可观测行动的博弈（不完全信息，但行动可观测，同时行动则不可观测），完美贝叶斯均衡可作为可观测行动的不完美信息动态博弈的标准解。



***序贯均衡******：***（每一步，每一个人条件期望效用最大化）1.序贯理性；2. 信念与行为一致（行为是通过信念的**贝叶斯法则**导出来的）

***完美均衡：*** 任何有限博弈都存在一个***完美（颤抖手）均衡***，完美均衡一定不会被若占优。

***奥曼-海萨尼教条***：1共同先验信念假设：人的先验信念一致； 2后验信念通过贝叶斯修正先验信念；（批判：先验信念异质性：基因）

（每个人都用后验概率利用贝叶斯修正先验概率，因为不完全信息，每个人都会过高估计世界的真实概率）

***奥曼定理***：people can not agree to disagree：不停地修正先验概率，后验概率一定会收敛。



## 合作博弈

在合作博弈中允许参与者互相协调，结盟以提高自身利益。合作博弈与非合作博弈的区别在于非合作博弈强调个体理性，而合作博弈强调集体理性。从另一个方面理解：存在具有约束力的合作协议的博弈就是合作博弈。

合作博弈形成条件：

1.联盟的整体收益大于每个个体单独经营收益之和

2.每个参与者都能获得比不加入联盟更高的收益

合作博弈的一般表示：
$[I, V]$ 是一个n人合作博亦， $I$ 表示n个参与者的集合, $\quad S$ 是 $I$ 的任意子集, 表示一个联盟,$V(S)$ 是这个n人合作博将的特征函数，描述了联盟的效益。

`定义 18.AA.3`：对于一个特征形博变 $(I, V)$ 和任何不相交的两个联盟 $S \subset I$ 和 $T \subset I$ (即,
$S \cap T=\varnothing$ )，如果我们有:
$$
\text { 若 } u^{S} \in V(S) \text { 和 } u^{T} \in V(T), \text { 则 }\left(u^{S}, u^{T}\right) \in V(S \cup T)
$$
那么，我们说这个特征形博变 (I,V) 是超可加的（superadditive）。
超可加性意味着，联盟 S 和 T 联合行动的结果至少与它们各自行动时的结果一样好。如果两个不相交联盟约定它们貌似仍然单独行动，那么超可加性成立。

`定义 18.AA.4`：一个可用特征形表示的效用可转移的（transferable utility）博奕（或称为 TU博亦）可用 $(I, v)$ 定义，其中: $I$ 是选手集 $; \quad v(\cdot)$ 是特征函数，该函数对每个非空联盟 $S \subset I$ 指定了一个数 $v(S), \quad v(S)$ 称为联盟 $S$ 的价值worth）。

### 大联盟合作博弈

大联盟结构是指合作博将的所有参与者在一个联盟内。n人合作博将 [I,V] 中，参与者i从n人大联盟 合作博亦所获得的收益 $\varphi_{i} \quad(V) \quad$ 应当满足三条基本原则：
(1) 对称性原则：参与者所获得的分配与其在集合中的排序位置无关。
(2) 有效性原则：若参与者对他所参与的任一合作都无贡献，则其分配应当为0; 所有的联盟收 入完全分配给其中的参与者。
(3) 可加性原则：n个人同时进行两项互不影响的合作，则两项合作的分配也应互不影响。

### 核

核试图描述的是，博弈的可能结果如何被联盟的竞争力量塑造出的

所谓核，是指具有下列性质的可行效用结果集：任何联盟依靠自身力量都不可能改进它的所有成员的收益。空的核意味着我们模拟的环境是竞争性不稳定的。如果核非空而且较小，那么我们可以说，联盟自身的竞争就能导致一个夏普利确定结果。如果核非空但较大，那么联盟竞争本身不可能大幅度缩小可能的结果范围。

定义 18.AA.5: 对于给定的特征形博卒 $(I, V)$ 和联盟 $S \subset I,$ 如果存在 $u^{\prime S} \in V(S)$ 使得对于 所有 $i \in S$ 都有 $u_{i}^{S}<u_{i}^{\prime S},$ 那么我们说，联盟 $S$ 阻止了（或能够改进）效用结果 $u \in \mathbb{R}^{I}$。如果博将是 TU 博亦 $(I, v)$ 那么结果 $u=\left(u_{1}, \ldots, u_{I}\right)$ 被 $S$ 阻止当且仅当 

$\sum_{i \in S} u_{i}<v(S)$

定义 18.AA.6：对于对最大联盟（全体参与人组成的联盟）可行的一个效用结果 $u=\left(u_{1}, \ldots, u_{I}\right)$ [即， $u \in V(I)$ ]来说，如果不存在能阻止 $u$ 的联盟，那么效用结果 $u$ 位于特征形博奕 $(I, V)$ 的核之中。

### 夏普利值

给定特征形博弈表示的策略性现实，如何划分合作收益才是合理的或“公平的”。

对于 $S h_{i}(I, v),$ 有一种直接而有趣的计算方法。介绍如下。对于任何 $S \subset I$ 和 $i \notin S$, 令 $m(S, i)=v(S \cup\{i\})-v(S)$ 为个人 $i$ 对联盟 $S$ 的边际贡献。 $^{ \text {(三十- } )}$ 对于 $I$ 中选手的任何次序$\pi$ (在数学上， $\pi$ 是个从 $I$ 到 $I$ 的一对一的函数)，以 $S(\pi, i) \subset I$ 表示在次序 $\pi$ 中位于选手 $i$ 之前的选手集[在数学上， $S(\pi, i)=\{h: \pi(h)<\pi(i)\}$ 。注意到，对于任何给定的次序 $\pi,$ 如果我们考虑每个选手 $i$ 对于次序 $\pi$ 中位于 $i$ 之前的选手集的边际贡献, 那么这些边际贡献的和 必定正好等于 $v(I) ;$ 也就是 $, \sum_{i \in I} m(S(\pi, i), i)=v(I)$ 。于是 $, \operatorname{Sh}_{i}(I, v)$ 是选手 $i$ 对于位于 $i$ 之前的选手集的平均边际贡献（average marginal contribution），注意这里是对所有次序进行平均（而且每个次序的权重相等）。由于总次序数为 I!，选手 $i$ 平均边际贡献的表达式为
$$
\operatorname{Sh}_{i}(I, v)=\frac{1}{I !} \sum_{\pi} m(S(\pi, i), i)
$$

其中，总和 $\sum_{\pi} m(S(\pi, i), i)$ 是加遍 $I$ 中选手的所有次序 $\pi$ 而得到的。

夏普利价值的一些基本性质。
（a）效率性。 $\sum_{i} S h_{i}(I, v)=v(I) ;$ 也就是说，不存在效用被浪费的现象。
（b）对称性。如果博将 $(I, v)$ 和 $\left(I, v^{\prime}\right)$ 相同，唯一不同是选手 $i$ 和 $h$ 的角色置换了 $,$ (三那么 $\operatorname{Sh}_{i}(I, v)=\operatorname{Sh}_{h}\left(I, v^{\prime}\right)$ 。用文字表达: 夏普利价值不取决于我们如何标记选手 $;$ 真正要紧的是特征函数描述的选手在博将中的位置。
（c）线性。从（18.AA.3）或（18.AA.4）可知，夏普利价值线性地取决于数据，也就是说，取决于定义博将的系数 $v(S)$
（d）显公理（dummy axiom）。假设选手 $i$ 对博亦没有任何贡献; 也就是说，对于所有 $S \subset I$ 都有 $v(S \cup\{i\})-v(S)=0$ 。于是 $\operatorname{Sh}_{i}(I, v)=0$ 。这个重要性质可从（18.AA.3）式直接得到：选手 $i$ 对任何联盟的边际贡献都为零; 因此，它的平均边际贡献也为零。



